{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 1: Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading data:\n",
    "file = Path ('Resources/myopia.csv')\n",
    "df = pd.read_csv(file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = df['MYOPIC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping MYOPIC column from the dataset\n",
    "df1=df.drop(['MYOPIC'], axis=1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardise the dataset so that columns with larger values don't influence the outcome more than columns with smaller values\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler_data = scaler.fit_transform(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the transformed data\n",
    "new_df1 = pd.DataFrame(scaler_data, columns=df1.columns)\n",
    "new_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the number of the features:\n",
    "new_df1.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2: Apply Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  dimensionality reduction\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# initialise PCA model with preserve 90% of the explained variance in dimensionality reduction\n",
    "pca = PCA (n_components=0.90)\n",
    "\n",
    "new_df1_pca = pca.fit_transform(new_df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the desired explained variance ratio\n",
    "pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the number of the features change\n",
    "new_df1_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using t-SNE to further reduce the dataset dimensions\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# initialise t-SNE model\n",
    "tsne = TSNE(n_components=3, random_state=42, learning_rate= 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce dimensions:\n",
    "tsne_features = tsne.fit_transform(new_df1_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the number of the features change:\n",
    "tsne_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare to plot the dataset \n",
    "\n",
    "plt.scatter(tsne_features[:,0], tsne_features[:,1], c =classes)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 3: Perform a Cluster Analysis with K-means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an elbow plot to identify the best number of clusters\n",
    "# Using a for loop to determine the inertia for each k between 1 and 10\n",
    "from sklearn.cluster import KMeans\n",
    "inertia =[]\n",
    "k = list (range(1,11))\n",
    "\n",
    "for i in k:\n",
    "    km = KMeans (n_clusters=i, random_state= 0)\n",
    "    km.fit (new_df1_pca)\n",
    "    inertia.append (km.inertia_)\n",
    "\n",
    "# Create the Elbow Curve using hvPlot\n",
    "elbow_data = {\"k\": k, \"inertia\": inertia}\n",
    "df_elbow = pd.DataFrame(elbow_data)\n",
    "df_elbow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the elbow:\n",
    "plt.plot (df_elbow['k'], df_elbow['inertia'])\n",
    "plt.xticks(range(1,11))\n",
    "plt.xlabel('Number of clusters (K)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Myopia Elbow Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8e511521329b140af7e6676783c3cc0389c71e3dac8fb02f046592fa68405aef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
